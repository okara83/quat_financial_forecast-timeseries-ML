{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE:  0.011755273677408695\n",
      "Epoch  0 MSE:  0.004931315779685974\n",
      "Epoch  0 MSE:  0.0006684156833216548\n",
      "Epoch  0 MSE:  0.00019513964070938528\n",
      "Epoch  0 MSE:  0.0024711473379284143\n",
      "Epoch  0 MSE:  0.002351084491237998\n",
      "Epoch  0 MSE:  0.000613000534940511\n",
      "Epoch  0 MSE:  0.0001293912500841543\n",
      "Epoch  0 MSE:  0.0012833632063120604\n",
      "Epoch  0 MSE:  0.0005460882093757391\n",
      "Epoch  0 MSE:  0.0001157425795099698\n",
      "Epoch  0 MSE:  0.0007005577208474278\n",
      "Epoch  0 MSE:  0.0006327348528429866\n",
      "Epoch  0 MSE:  0.004436605144292116\n",
      "Epoch  0 MSE:  0.0044382656924426556\n",
      "Epoch  0 MSE:  0.011763432063162327\n",
      "Epoch  0 MSE:  0.0021887582261115313\n",
      "Epoch  0 MSE:  0.00048511161003261805\n",
      "Epoch  0 MSE:  0.0025920276530086994\n",
      "Epoch  0 MSE:  0.010195807553827763\n",
      "Epoch  0 MSE:  0.009402770549058914\n",
      "Epoch  0 MSE:  0.0026213214732706547\n",
      "Epoch  0 MSE:  0.0004667737812269479\n",
      "Epoch  0 MSE:  0.007124699652194977\n",
      "Epoch  0 MSE:  0.02380404621362686\n",
      "Epoch  0 MSE:  0.050487782806158066\n",
      "Epoch  0 MSE:  0.05441397428512573\n",
      "Epoch  0 MSE:  0.03981567919254303\n",
      "Epoch  0 MSE:  0.03035861998796463\n",
      "Epoch  0 MSE:  0.011466695927083492\n",
      "Epoch  0 MSE:  0.0003034650580957532\n",
      "Epoch  0 MSE:  0.012652023695409298\n",
      "Epoch  0 MSE:  0.025568705052137375\n",
      "Epoch  0 MSE:  0.017042260617017746\n",
      "Epoch  0 MSE:  0.005680684000253677\n",
      "Epoch  0 MSE:  0.000809091841802001\n",
      "Epoch  0 MSE:  0.00046554021537303925\n",
      "Epoch  0 MSE:  0.005882228258997202\n",
      "Epoch  0 MSE:  0.00857821386307478\n",
      "Epoch  0 MSE:  0.011019558645784855\n",
      "Epoch  0 MSE:  0.013880847953259945\n",
      "Epoch  0 MSE:  0.016154488548636436\n",
      "Epoch  0 MSE:  0.013489332050085068\n",
      "Epoch  0 MSE:  0.012578696012496948\n",
      "Epoch  0 MSE:  0.0018142317421734333\n",
      "Epoch  0 MSE:  0.002822043839842081\n",
      "Epoch  0 MSE:  0.04544168338179588\n",
      "Epoch  0 MSE:  0.01919098198413849\n",
      "Epoch  0 MSE:  0.0023080348037183285\n",
      "Epoch  0 MSE:  0.00012638658517971635\n",
      "Epoch  0 MSE:  0.00013264174049254507\n",
      "Epoch  0 MSE:  0.00039681894122622907\n",
      "Epoch  0 MSE:  0.00023077157675288618\n",
      "Epoch  0 MSE:  0.0008785623358562589\n",
      "Epoch  0 MSE:  0.0005410194280557334\n",
      "Epoch  0 MSE:  0.0009341782424598932\n",
      "Epoch  0 MSE:  0.0037990068085491657\n",
      "Epoch  0 MSE:  0.02073412947356701\n",
      "Epoch  0 MSE:  0.028370864689350128\n",
      "Epoch  0 MSE:  0.008912188932299614\n",
      "Epoch  0 MSE:  0.001545698381960392\n",
      "Epoch  0 MSE:  0.0006728179287165403\n",
      "Epoch  0 MSE:  0.004907227121293545\n",
      "Epoch  0 MSE:  0.010262188501656055\n",
      "Epoch  0 MSE:  0.010147437453269958\n",
      "Epoch  0 MSE:  0.0024977789726108313\n",
      "Epoch  0 MSE:  0.008177795447409153\n",
      "Epoch  0 MSE:  0.028757229447364807\n",
      "Epoch  0 MSE:  0.023778095841407776\n",
      "Epoch  0 MSE:  0.010927234776318073\n",
      "Epoch  0 MSE:  0.008351991884410381\n",
      "Epoch  0 MSE:  0.0021391098853200674\n",
      "Epoch  0 MSE:  0.025443442165851593\n",
      "Epoch  0 MSE:  0.03857825696468353\n",
      "Epoch  0 MSE:  0.015586822293698788\n",
      "Epoch  0 MSE:  0.008288202807307243\n",
      "Epoch  0 MSE:  0.000120925935334526\n",
      "Epoch  0 MSE:  0.00585685670375824\n",
      "Epoch  0 MSE:  0.011318396776914597\n",
      "Epoch  0 MSE:  0.012295126914978027\n",
      "Epoch  0 MSE:  0.013207375071942806\n",
      "Epoch  0 MSE:  0.007997695356607437\n",
      "Epoch  0 MSE:  0.006280171684920788\n",
      "Epoch  0 MSE:  0.004934139549732208\n",
      "Epoch  0 MSE:  0.001276765251532197\n",
      "Epoch  0 MSE:  0.00022472524142358452\n",
      "Epoch  0 MSE:  0.0005047140875831246\n",
      "Epoch  0 MSE:  0.002721283119171858\n",
      "Epoch  0 MSE:  0.0024037298280745745\n",
      "Epoch  0 MSE:  0.0006086218636482954\n",
      "Epoch  0 MSE:  0.001184220309369266\n",
      "Epoch  0 MSE:  8.108007750706747e-05\n",
      "Epoch  0 MSE:  0.00040033695404417813\n",
      "Epoch  0 MSE:  0.0005832338938489556\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b5e23ddd5cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MSE: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd.variable import Variable\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available()  else 'cpu'\n",
    "\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "### Parameters\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "\n",
    "input_dim = 5\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "num_epochs = 100\n",
    "lookback = 144 # choose sequence length\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "### Functions \n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "def split_data(stock, lookback):\n",
    "    data_raw = stock.to_numpy() # convert to numpy array Do not need this if you run minmaxscaler\n",
    "  #  data_raw = stock\n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - lookback): \n",
    "        data.append(data_raw[index: index + lookback])\n",
    "    \n",
    "    data = np.array(data);\n",
    "    #print(data.shape)\n",
    "    test_set_size = int(np.round(0.2*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (test_set_size);\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,-1]\n",
    "    \n",
    "    x_test = data[train_set_size:,:-1]\n",
    "    y_test = data[train_set_size:,-1,-1]\n",
    "    \n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "    \n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, pred, transform=None):\n",
    "        self.data = data.float()\n",
    "        self.pred = pred.float()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.pred[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            y = self.transform(y)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "        \n",
    "\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "## Training process\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")[-10000:]\n",
    "data.max(axis=0)\n",
    "data.min(axis=0)\n",
    "minmax = MinMaxScaler()\n",
    "\n",
    "######\n",
    "#Only do this if you are using all the columns\n",
    "#Choose columns which you want \n",
    "data[['1','2','3','4','5']] = minmax.fit_transform(data[['1', '2', '3', '4' ,'5']])\n",
    "#######\n",
    "\n",
    "# Picking a day to predict the stock prices for the 10 mins of the next day\n",
    "price = data[['1', '2', '3', '4', '5']]\n",
    "x_train, y_train, x_test, y_test = split_data(price, lookback)\n",
    "\n",
    "x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "y_train= torch.from_numpy(y_train).type(torch.Tensor).view(-1,1)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor).view(-1,1)\n",
    "\n",
    "dataset = MyDataset(x_train, y_train)\n",
    "loader = DataLoader(dataset, batch_size = 32, shuffle = False)\n",
    "\n",
    "\n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "hist = np.zeros(num_epochs)\n",
    "start_time = time.time()\n",
    "error = []\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    #Minibatching for Stochastic Gradient Descent \n",
    "    for n_batch, batch in enumerate(loader):\n",
    "        n_data = Variable(batch[0], requires_grad=True)\n",
    "        ground_truth = Variable(batch[1], requires_grad=True)\n",
    "        optimizer.zero_grad()\n",
    "        y_train_pred = model(n_data)\n",
    "        loss = criterion(y_train_pred, ground_truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    error.append(loss)\n",
    "    hist[t] = loss.item()\n",
    "    \n",
    "    \n",
    " \n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "#### compute error and create output file\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "\n",
    "prediction = torch.reshape(prediction, [1,len(prediction)]).tolist()[0]\n",
    "truth = [elem[0] for elem in y_train.tolist()]\n",
    "\n",
    "rmse = mean_squared_error(truth,prediction)\n",
    "\n",
    "df = pd.DataFrame({'Real Price': truth,\n",
    "                   'Predicted Price': prediction,\n",
    "                   'RMS Error': [rmse]+['']*(len(truth)-1)})\n",
    "df.to_csv('out_5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
